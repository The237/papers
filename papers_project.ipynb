{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7//irw4kIW66nJvhF/xJX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The237/papers/blob/master/papers_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objet\n",
        "\n",
        "Contenir tous les codes sources d'expérimentation des implémentations sur le projet d'automatisation de la revue systématique nommé PAPERS."
      ],
      "metadata": {
        "id": "V5LWUkeK3rWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes definition"
      ],
      "metadata": {
        "id": "AXJapnfGBYBn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iGXkhpww3mZP"
      },
      "outputs": [],
      "source": [
        "class Article:\n",
        "    \"\"\"\n",
        "    The Article class represents an article.\n",
        "\n",
        "    Attributes:\n",
        "        title (str): The title of the article.\n",
        "        abstract (str): The abstract of the article.\n",
        "        keywords (list, optional): A list of keywords associated with the article. Defaults to an empty list.\n",
        "        content (str, optional): The content of the article. Defaults to an empty string.\n",
        "        metadata (object, optional): Additional metadata associated with the article. Defaults to None.\n",
        "\n",
        "    Methods:\n",
        "        get_title():\n",
        "            Returns the title of the article.\n",
        "        get_abstract():\n",
        "            Returns the abstract of the article.\n",
        "        get_keywords():\n",
        "            Returns the keywords associated with the article.\n",
        "        get_content():\n",
        "            Returns the content of the article.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, title, abstract, keywords=None, content=None, metadata=None):\n",
        "        \"\"\"\n",
        "        Initializes an instance of the Article class.\n",
        "\n",
        "        Args:\n",
        "            title (str): The title of the article.\n",
        "            abstract (str): The abstract of the article.\n",
        "            keywords (list, optional): A list of keywords associated with the article. Defaults to an empty list.\n",
        "            content (str, optional): The content of the article. Defaults to an empty string.\n",
        "            metadata (object, optional): Additional metadata associated with the article. Defaults to None.\n",
        "\n",
        "        \"\"\"\n",
        "        self.title = title\n",
        "        self.abstract = abstract\n",
        "        self.keywords = keywords if keywords else []\n",
        "        self.content = content if content else ''\n",
        "        self.metadata = metadata if metadata else ''\n",
        "\n",
        "    def get_title(self):\n",
        "        \"\"\"\n",
        "        Returns the title of the article.\n",
        "\n",
        "        Returns:\n",
        "            title (str): The title of the article.\n",
        "\n",
        "        \"\"\"\n",
        "        return self.title\n",
        "\n",
        "    def get_abstract(self):\n",
        "        \"\"\"\n",
        "        Returns the abstract of the article.\n",
        "\n",
        "        Returns:\n",
        "            abstract (str): The abstract of the article.\n",
        "\n",
        "        \"\"\"\n",
        "        return self.abstract\n",
        "\n",
        "    def get_keywords(self):\n",
        "        \"\"\"\n",
        "        Returns the keywords associated with the article.\n",
        "\n",
        "        Returns:\n",
        "            keywords (list): A list of keywords associated with the article.\n",
        "\n",
        "        \"\"\"\n",
        "        return self.keywords\n",
        "\n",
        "    def get_content(self):\n",
        "        \"\"\"\n",
        "        Returns the content of the article.\n",
        "\n",
        "        Returns:\n",
        "            content (str): The content of the article.\n",
        "\n",
        "        \"\"\"\n",
        "        return self.content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "class ArticleCleaner:\n",
        "    \"\"\"\n",
        "    The ArticleCleaner class represents a cleaner for articles.\n",
        "\n",
        "    Attributes:\n",
        "        custom_stopwords (list, optional): A list of custom stopwords to be added. Defaults to None.\n",
        "\n",
        "    Methods:\n",
        "        clean_article(article):\n",
        "            Cleans the given article by removing stopwords and punctuation.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, custom_stopwords=None):\n",
        "        \"\"\"\n",
        "        Initializes an instance of the ArticleCleaner class.\n",
        "\n",
        "        Args:\n",
        "            custom_stopwords (list, optional): A list of custom stopwords to be added. Defaults to None.\n",
        "\n",
        "        \"\"\"\n",
        "        self.custom_stopwords = custom_stopwords if custom_stopwords else []\n",
        "\n",
        "    def clean_article(self, article):\n",
        "        \"\"\"\n",
        "        Cleans the given article by removing stopwords and punctuation.\n",
        "\n",
        "        Args:\n",
        "            article (str): The article to be cleaned.\n",
        "\n",
        "        Returns:\n",
        "            cleaned_article (str): The cleaned version of the article.\n",
        "\n",
        "        \"\"\"\n",
        "        # Tokenisation du contenu de l'article en mots individuels\n",
        "        tokens = word_tokenize(article)\n",
        "\n",
        "        # Chargement des stopwords anglais\n",
        "        nltk.download('stopwords')\n",
        "        english_stopwords = set(stopwords.words('english'))\n",
        "\n",
        "        # Chargement des éléments de ponctuation\n",
        "        punctuation = set(string.punctuation)\n",
        "\n",
        "        # Création de l'ensemble de stopwords comprenant les stopwords anglais et les stopwords spécifiques de l'auteur\n",
        "        stopwords_set = english_stopwords.union(self.custom_stopwords)\n",
        "\n",
        "        # Suppression des stopwords et des éléments de ponctuation\n",
        "        filtered_tokens = [word for word in tokens if word.lower() not in stopwords_set and word not in punctuation]\n",
        "\n",
        "        # Reconstitution du contenu nettoyé\n",
        "        cleaned_article = ' '.join(filtered_tokens)\n",
        "\n",
        "        return cleaned_article"
      ],
      "metadata": {
        "id": "2yR-8gdE8aQn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Doc2Vec\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "class ArticleVectorizer:\n",
        "    \"\"\"\n",
        "    The ArticleVectorizer class represents a vectorizer for converting articles into feature vectors.\n",
        "\n",
        "    Attributes:\n",
        "        method (str): The vectorization method to use. Valid options are 'tfidf', 'bert', or 'doc2vec'.\n",
        "\n",
        "    Methods:\n",
        "        vectorize_article(article):\n",
        "            Vectorizes the given article based on the specified method.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, method='tfidf'):\n",
        "        \"\"\"\n",
        "        Initializes an instance of the ArticleVectorizer class.\n",
        "\n",
        "        Args:\n",
        "            method (str, optional): The vectorization method to use. Defaults to 'tfidf'.\n",
        "\n",
        "        \"\"\"\n",
        "        self.method = method\n",
        "        if self.method == 'bert':\n",
        "            self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "            self.model = BertModel.from_pretrained('bert-base-uncased')\n",
        "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "        elif self.method == 'doc2vec':\n",
        "            self.model = Doc2Vec.load('doc2vec_model')  # Charger le modèle Doc2Vec entraîné\n",
        "\n",
        "    def vectorize_article(self, article):\n",
        "        \"\"\"\n",
        "        Vectorizes the given article based on the specified method.\n",
        "\n",
        "        Args:\n",
        "            article (str): The article to be vectorized.\n",
        "\n",
        "        Returns:\n",
        "            vectorized_article (object): The vectorized representation of the article.\n",
        "\n",
        "        \"\"\"\n",
        "        if self.method == 'tfidf':\n",
        "            # Utiliser la méthode TF-IDF\n",
        "            vectorizer = TfidfVectorizer()\n",
        "            vectorized_article = vectorizer.fit_transform([article])\n",
        "        elif self.method == 'bert':\n",
        "            # Utiliser BERT\n",
        "            encoding = self.tokenizer.encode_plus(\n",
        "                article,\n",
        "                add_special_tokens=True,\n",
        "                max_length=512,\n",
        "                truncation=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            input_ids = encoding['input_ids'].to(self.device)\n",
        "            attention_mask = encoding['attention_mask'].to(self.device)\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask)\n",
        "                vectorized_article = torch.mean(outputs.last_hidden_state, dim=1)\n",
        "        elif self.method == 'doc2vec':\n",
        "            # Utiliser Doc2Vec\n",
        "            vectorized_article = self.model.infer_vector(article.split())\n",
        "\n",
        "        return vectorized_article"
      ],
      "metadata": {
        "id": "NoI2_g_i-a-6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances, cosine_distances\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class ArticleDistanceCalculator:\n",
        "    \"\"\"\n",
        "    The ArticleDistanceCalculator class represents a calculator for calculating the distance between two articles.\n",
        "\n",
        "    Attributes:\n",
        "        None\n",
        "\n",
        "    Methods:\n",
        "        calculate_distance(article1, article2, metric='euclidean'):\n",
        "            Calculates the distance between two articles based on the specified metric.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def calculate_distance(self, article1, article2, metric='euclidean'):\n",
        "        \"\"\"\n",
        "        Calculates the distance between two articles based on the specified metric.\n",
        "\n",
        "        Args:\n",
        "            article1 (str): The first article.\n",
        "            article2 (str): The second article.\n",
        "            metric (str, optional): The distance metric to use. Valid options are 'euclidean', 'manhattan',\n",
        "                'cosine', or 'cosine_similarity'. Defaults to 'euclidean'.\n",
        "\n",
        "        Returns:\n",
        "            float: The distance between the two articles.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If an invalid metric is specified.\n",
        "\n",
        "        \"\"\"\n",
        "        # Conversion des articles en vecteurs de caractéristiques\n",
        "        vectorizer = ArticleVectorizer()\n",
        "        vectorized_article1 = vectorizer.vectorize_article(article1)\n",
        "        vectorized_article2 = vectorizer.vectorize_article(article2)\n",
        "\n",
        "        # Calcul de la distance entre les articles\n",
        "        if metric == 'euclidean':\n",
        "            distance = euclidean_distances(vectorized_article1, vectorized_article2)[0][0]\n",
        "        elif metric == 'manhattan':\n",
        "            distance = manhattan_distances(vectorized_article1, vectorized_article2)[0][0]\n",
        "        elif metric == 'cosine':\n",
        "            distance = cosine_distances(vectorized_article1, vectorized_article2)[0][0]\n",
        "        elif metric == 'cosine_similarity':\n",
        "            similarity = cosine_similarity(vectorized_article1, vectorized_article2)[0][0]\n",
        "            distance = 1 - similarity\n",
        "        else:\n",
        "            raise ValueError(\"Invalid metric. Please specify 'euclidean', 'manhattan', 'cosine', or 'cosine_similarity'.\")\n",
        "\n",
        "        return distance"
      ],
      "metadata": {
        "id": "4Xpl7u3w_lBR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ArticleClassifier:\n",
        "    \"\"\"\n",
        "    The ArticleClassifier class represents the classification of an article based on a distance metric and a threshold.\n",
        "\n",
        "    Attributes:\n",
        "        None\n",
        "\n",
        "    Methods:\n",
        "        classify_article(distance, threshold):\n",
        "            Classifies the article based on the given distance and threshold.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def classify_article(self, distance, threshold):\n",
        "        \"\"\"\n",
        "        Classifies the article based on the given distance and threshold.\n",
        "\n",
        "        Args:\n",
        "            distance (float): The distance between the article and a reference.\n",
        "            threshold (float): The threshold value for classification.\n",
        "\n",
        "        Returns:\n",
        "            str: The classification of the article. It can be \"Classe A\" if the distance is less than or equal to\n",
        "            the threshold, or \"Classe B\" otherwise.\n",
        "\n",
        "        \"\"\"\n",
        "        if distance <= threshold:\n",
        "            classification = \"Classe A\"\n",
        "        else:\n",
        "            classification = \"Classe B\"\n",
        "\n",
        "        return classification"
      ],
      "metadata": {
        "id": "vvXhnzqgAgpw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes Test"
      ],
      "metadata": {
        "id": "sL6Y1aWEBebO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2cmmr0YTBgpD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}